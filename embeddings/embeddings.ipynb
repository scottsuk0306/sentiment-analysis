{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68d8f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path + \"\\src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f6a9ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>one review ha mention watch 1 oz episod youll ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wonder littl product film techniqu veri unassu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thought thi wa wonder way spend time hot summe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>basic famili littl boy jake think zombi hi clo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>probabl alltim favorit movi stori selfless sac...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>sure would like see resurrect date seahunt ser...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>thi show wa amaz fresh innov idea 70 first air...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>encourag posit comment thi film wa look forwar...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>like origin gut wrench laughter like thi movi ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review sentiment\n",
       "0           0  one review ha mention watch 1 oz episod youll ...  positive\n",
       "1           1  wonder littl product film techniqu veri unassu...  positive\n",
       "2           2  thought thi wa wonder way spend time hot summe...  positive\n",
       "3           3  basic famili littl boy jake think zombi hi clo...  negative\n",
       "4           4  petter mattei love time money visual stun film...  positive\n",
       "5           5  probabl alltim favorit movi stori selfless sac...  positive\n",
       "6           6  sure would like see resurrect date seahunt ser...  positive\n",
       "7           7  thi show wa amaz fresh innov idea 70 first air...  negative\n",
       "8           8  encourag posit comment thi film wa look forwar...  negative\n",
       "9           9  like origin gut wrench laughter like thi movi ...  positive"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocess import normalize_text\n",
    "import pandas as pd\n",
    "\n",
    "imdb_data=pd.read_csv('../data/normalized IMDB dataset.csv')\n",
    "imdb_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "feb959ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,) (40000,)\n",
      "(10000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#split the dataset  \n",
    "#train dataset\n",
    "X_train=imdb_data.review[:40000]\n",
    "y_train=imdb_data.sentiment[:40000]\n",
    "#test dataset\n",
    "X_test=imdb_data.review[40000:]\n",
    "y_test=imdb_data.sentiment[40000:]\n",
    "print(X_test.shape,train_sentiments.shape)\n",
    "print(y_test.shape,test_sentiments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad98ce9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    one review ha mention watch 1 oz episod youll ...\n",
       "1    wonder littl product film techniqu veri unassu...\n",
       "2    thought thi wa wonder way spend time hot summe...\n",
       "3    basic famili littl boy jake think zombi hi clo...\n",
       "4    petter mattei love time money visual stun film...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44452096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 50 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = Word2Vec(sentences=train_reviews, vector_size=100, window=5, min_count=2, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e852605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('q', 0.3575131297111511), ('s', 0.3396383225917816), ('c', 0.3324417471885681), ('v', 0.3321092426776886), ('\\\\', 0.28555160760879517), ('x', 0.2762637734413147), ('t', 0.25818371772766113), ('p', 0.23691241443157196), ('g', 0.17745226621627808), (']', 0.17706088721752167)]\n"
     ]
    }
   ],
   "source": [
    "model_result = model.wv.most_similar(\"f\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43bfa877",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39msave_word2vec_format(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meng_w2v_cbow\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# 모델 저장\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mKeyedVectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meng_w2v_cbow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch-gpu\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1723\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1678\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1679\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1680\u001b[0m     ):\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1682\u001b[0m \n\u001b[0;32m   1683\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \n\u001b[0;32m   1722\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch-gpu\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2073\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2069\u001b[0m         _word2vec_read_binary(\n\u001b[0;32m   2070\u001b[0m             fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[0;32m   2071\u001b[0m         )\n\u001b[0;32m   2072\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2073\u001b[0m         \u001b[43m_word2vec_read_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kv\u001b[38;5;241m.\u001b[39mvectors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(kv):\n\u001b[0;32m   2075\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   2076\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduplicate words detected, shrinking matrix size from \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2077\u001b[0m         kv\u001b[38;5;241m.\u001b[39mvectors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlen\u001b[39m(kv),\n\u001b[0;32m   2078\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch-gpu\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1978\u001b[0m, in \u001b[0;36m_word2vec_read_text\u001b[1;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m line \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected end of input; is count incorrect or file otherwise damaged?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1978\u001b[0m word, weights \u001b[38;5;241m=\u001b[39m \u001b[43m_word2vec_line_to_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1979\u001b[0m _add_word_to_kv(kv, counts, word, weights, vocab_size)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch-gpu\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1984\u001b[0m, in \u001b[0;36m_word2vec_line_to_vector\u001b[1;34m(line, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[0;32m   1982\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_word2vec_line_to_vector\u001b[39m(line, datatype, unicode_errors, encoding):\n\u001b[0;32m   1983\u001b[0m     parts \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_unicode(line\u001b[38;5;241m.\u001b[39mrstrip(), encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39municode_errors)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1984\u001b[0m     word, weights \u001b[38;5;241m=\u001b[39m parts[\u001b[38;5;241m0\u001b[39m], [datatype(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m parts[\u001b[38;5;241m1\u001b[39m:]]\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m word, weights\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch-gpu\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1984\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1982\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_word2vec_line_to_vector\u001b[39m(line, datatype, unicode_errors, encoding):\n\u001b[0;32m   1983\u001b[0m     parts \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_unicode(line\u001b[38;5;241m.\u001b[39mrstrip(), encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39municode_errors)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1984\u001b[0m     word, weights \u001b[38;5;241m=\u001b[39m parts[\u001b[38;5;241m0\u001b[39m], [\u001b[43mdatatype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m parts[\u001b[38;5;241m1\u001b[39m:]]\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m word, weights\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "model.wv.save_word2vec_format('eng_w2v_cbow') # 모델 저장\n",
    "\n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v_cbow\") # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dbf764",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = loaded_model.most_similar(\"good\")\n",
    "print(model_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
